{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-fd17fbbc4501>:4: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n",
      "  column_as_df = json_normalize(df[column])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22264, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_json(\"sample_file.json\")\n",
    "    \n",
    "for column in ['Issues']:\n",
    "    column_as_df = json_normalize(df[column])\n",
    "    column_as_df.columns = [str(column+\"_\"+subcolumn) for subcolumn in column_as_df.columns]\n",
    "    df = df.drop(column, axis=1).merge(column_as_df, right_index=True, left_index=True)\n",
    "\n",
    "## function allows to keep the index if we need to merge on the orginal data.\n",
    "df = pd.DataFrame([dict(y, index=i) for i, x in enumerate(df['Issues_Messages'].values.tolist()) for y in x])\n",
    "\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataFrameList(df,target_column,separator):\n",
    "    def split_text(line, separator):\n",
    "        splited_line =  [e+d for e in line.split(separator) if e]\n",
    "        return splited_line\n",
    "    \n",
    "    def splitListToRows(row,row_accumulator,target_column,separator):\n",
    "        split_row = row[target_column].split(separator)\n",
    "        for s in split_row:\n",
    "            new_row = row.to_dict()\n",
    "            new_row[target_column] = s\n",
    "            row_accumulator.append(new_row)\n",
    "    new_rows = []\n",
    "    df.apply(splitListToRows,axis=1,args = (new_rows,target_column,separator))\n",
    "    new_df = pd.DataFrame(new_rows)\n",
    "    return new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select representative threads...\n",
      "split sentenses on punctuation...\n",
      "Text Cleaning using simple regex...\n",
      "calculate nb words of sentenses...\n",
      "count occurence of sentenses...\n",
      "remove duplicates (keep last)...\n",
      "(8560, 5)\n"
     ]
    }
   ],
   "source": [
    "new_df = df\n",
    "\n",
    "print(\"select representative threads...\")\n",
    "new_df = new_df[new_df.IsFromCustomer==False]\n",
    "\n",
    "print(\"split sentenses on punctuation...\")\n",
    "for sep in ['. ',', ','? ', '! ', '; ']:\n",
    "    new_df = splitDataFrameList(new_df, 'Text', sep)\n",
    "\n",
    "print(\"Text Cleaning using simple regex...\")\n",
    "new_df['Text']=new_df['Text'].apply(lambda x: \" \".join(x.split()))\n",
    "new_df['Text']=new_df['Text'].apply(lambda x: x.strip(\".\"))\n",
    "new_df['Text']=new_df['Text'].apply(lambda x: \" \".join(x.split()))\n",
    "new_df['Text']=new_df['Text'].apply(lambda x: x.replace(' i ',' I '))\n",
    "new_df['Text']=new_df['Text'].apply(lambda x: x.replace(' ?','?'))\n",
    "new_df['Text']=new_df['Text'].apply(lambda x: x.replace(' !','!'))\n",
    "new_df['Text']=new_df['Text'].apply(lambda x: x.replace(' .','.'))\n",
    "new_df['Text']=new_df['Text'].apply(lambda x: x.replace('OK','Ok'))\n",
    "new_df['Text']=new_df['Text'].apply(lambda x: x[0].upper()+x[1:])\n",
    "new_df['Text']=new_df['Text'].apply(lambda x: x+\"?\" if re.search(r'^(Wh|How).+([^?])$',x) else x)\n",
    "\n",
    "print(\"calculate nb words of sentenses...\")\n",
    "new_df['nb_words'] = new_df['Text'].apply(lambda x: len(str(x).split(' ')))\n",
    "new_df = new_df[new_df['nb_words']>2]\n",
    "\n",
    "print(\"count occurence of sentenses...\")\n",
    "new_df['Counts'] = new_df.groupby(['Text'])['Text'].transform('count')\n",
    "\n",
    "print(\"remove duplicates (keep last)...\")\n",
    "new_df = new_df.drop_duplicates(subset=['Text'], keep='last')\n",
    "\n",
    "new_df = new_df.reset_index(drop=True)\n",
    "print(new_df.shape)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf_matrice  (8560, 99397)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TfidfVectorizer(min_df=0, ngram_range=(1, 5)),\n",
       " <8560x99397 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 271975 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tf = TfidfVectorizer(analyzer='word',ngram_range=(1, 5), min_df=0)\n",
    "tfidf_matrice = model_tf.fit_transform(new_df['Text'])\n",
    "print(\"tfidf_matrice \", tfidf_matrice.shape)\n",
    "model_tf, tfidf_matrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_completions(prefix_string, data, model_tf, tfidf):\n",
    "        \n",
    "    prefix_string = str(prefix_string)              #make a copy of the prefix index\n",
    "    new_df = data.reset_index(drop=True)            #resets indexes to cover the removed elements\n",
    "\n",
    "    #giving more weight to those phrases that occure more frequently\n",
    "\n",
    "    weights = new_df['Counts'].apply(lambda x: 1+ np.log1p(x)).values      \n",
    "\n",
    "\n",
    "\n",
    "    # tranform the string using the tfidf model\n",
    "    tfidf_spelling = model_tf.transform([prefix_string])\n",
    "    # calculate cosine_matrix\n",
    "    # to find the similarity between the string and dataframe\n",
    "    cosine_similarite = linear_kernel(tfidf, tfidf_spelling)\n",
    "\n",
    "    #sort by order of similarity from 1 to 0:\n",
    "    similarity_scores = list(enumerate(cosine_similarite))\n",
    "    similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "    #selects top 10\n",
    "    similarity_scores = similarity_scores[0:10]\n",
    "    #print (similarity_scores)\n",
    "\n",
    "    similarity_scores = [i for i in similarity_scores]\n",
    "    similarity_indices = [i[0] for i in similarity_scores]\n",
    "    #print(similarity_indices)\n",
    "    #print(similarity_scores)\n",
    "\n",
    "    #add weight to the potential results that had high frequency in orig data\n",
    "    for i in range(len(similarity_scores)):\n",
    "        similarity_scores[i][1][0]=similarity_scores[i][1][0]*weights[similarity_indices][i]\n",
    "\n",
    "    #sort in terms of score\n",
    "\n",
    "    similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "    #select top 3 suggestions\n",
    "    similarity_scores = similarity_scores[0:3]\n",
    "    #obtain the indexes of the top suggestions\n",
    "    similarity_indices_w = [i[0] for i in similarity_scores]\n",
    "\n",
    "    #print(similarity_scores)\n",
    "    #returns the top suggestions form the dataframe\n",
    "    return new_df.loc[similarity_indices_w]['Text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is your     \n",
      " \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['What is your account number?',\n",
       " 'What is your order number?',\n",
       " 'What is your phone number?']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix = 'What is your'\n",
    "\n",
    "print(prefix,\"    \\n \")\n",
    "\n",
    "generate_completions(prefix, new_df, model_tf,tfidf_matrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
