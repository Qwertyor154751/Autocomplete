{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "from nltk.corpus import brown\n",
    "from nltk.corpus import reuters\n",
    "import nltk\n",
    "from nltk.corpus import PlaintextCorpusReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trigram_freq(tokens):\n",
    "\ttgs = list(nltk.trigrams(tokens))\n",
    "\n",
    "\ta,b,c = list(zip(*tgs))\n",
    "\tbgs = list(zip(a,b))\n",
    "\treturn nltk.ConditionalFreqDist(list(zip(bgs, c)))\n",
    "\n",
    "def get_bigram_freq(tokens):\n",
    "\tbgs = list(nltk.bigrams(tokens))\n",
    "\n",
    "\treturn nltk.ConditionalFreqDist(bgs)\n",
    "\n",
    "def appendwithcheck ( preds, to_append):\n",
    "\tfor pred in preds:\n",
    "\t    if pred[0] == to_append[0]:\n",
    "\t        return\n",
    "\tpreds.append(to_append)\n",
    "\n",
    "\n",
    "def incomplete_pred(words, n):\n",
    "\tall_succeeding = bgs_freq[(words[n-2])].most_common()\n",
    "\t#print (all_succeeding, file=sys.stderr)\n",
    "\tpreds = []\n",
    "\tnumber=0\n",
    "\tfor pred in all_succeeding:\n",
    "\t    if pred[0].startswith(words[n-1]):\n",
    "\t        appendwithcheck(preds, pred)\n",
    "\t        number+=1\n",
    "\t    if number==3:\n",
    "\t        return preds\n",
    "\tif len(preds)<3:\n",
    "\t    med=[]\n",
    "\t    for pred in all_succeeding:\n",
    "\t        med.append((pred[0], nltk.edit_distance(pred[0],words[n-1], transpositions=True)))\n",
    "\t    med.sort(key=lambda x:x[1])\n",
    "\t    index=0\n",
    "\t    while len(preds)<3:\n",
    "\t        print (index, len(med))\n",
    "\t        if index<len(med):\n",
    "\t            if med[index][1]>0:\n",
    "\t                appendwithcheck(preds, med[index])\n",
    "\t            index+=1\n",
    "\t        if index>=len(preds):\n",
    "\t            return preds\n",
    "\n",
    "\n",
    "new_corpus = PlaintextCorpusReader('./','.*')\n",
    "tokens = brown.words() + new_corpus.words('chat.txt')\n",
    "\n",
    "bgs_freq = get_bigram_freq(tokens)\n",
    "tgs_freq = get_trigram_freq(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\Vineeth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\brown.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PlaintextCorpusReader in 'F:\\\\pro\\\\misc\\\\NLP'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "enter = \"What is for\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tgs -> [('the', 12), ('a', 6), ('you', 3), ('any', 2), ('sale', 2)]\n",
      "['the', 'a', 'you', 'any', 'sale']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[('the', 12), ('a', 6), ('you', 3), ('any', 2), ('sale', 2)]\n"
     ]
    }
   ],
   "source": [
    "work = \"pred\"\n",
    "string = enter \n",
    "words = string.split()\n",
    "n = len(words)\n",
    "if work == \"pred\":\n",
    "    if n == 1:\n",
    "        bgs = bgs_freq[(string)].most_common(5)\n",
    "        b = []\n",
    "        for i in bgs:\n",
    "            b.append(i[0])\n",
    "        #print(pred)\n",
    "        print(\"bgs ->\" , bgs)\n",
    "    elif n>1:\n",
    "        print (tgs_freq[(words[n-2],words[n-1])].most_common(5),file=sys.stderr)\n",
    "        tgs = tgs_freq[(words[n-2],words[n-1])].most_common(5)\n",
    "        print(\"tgs ->\" , tgs)\n",
    "\n",
    "        pred = []\n",
    "        for i in tgs:\n",
    "            pred.append(i[0])\n",
    "        print(pred)\n",
    "\n",
    "else:\n",
    "    inc = incomplete_pred(words, n)\n",
    "    print(\"inc ->\" , inc)\n",
    "\n",
    "if n == 1:\n",
    "    p = b\n",
    "else:\n",
    "    p = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'a', 'you', 'any', 'sale']\n"
     ]
    }
   ],
   "source": [
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
