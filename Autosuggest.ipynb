{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enchant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.metrics import edit_distance\n",
    "\n",
    "class SpellingReplacer:\n",
    "    def __init__(self, dict_name='en_US', max_dist=2):\n",
    "        self.spell_dict = enchant.Dict(dict_name)\n",
    "        self.max_dist = 2\n",
    "\n",
    "    def replace(self, word):\n",
    "        if self.spell_dict.check(word):\n",
    "            return word\n",
    "        suggestions = self.spell_dict.suggest(word)\n",
    "\n",
    "        if suggestions and edit_distance(word, suggestions[0]) <= self.max_dist:\n",
    "            return suggestions[0]\n",
    "        else:\n",
    "            return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spell_check(word_list):\n",
    "    checked_list = []\n",
    "    for item in word_list:\n",
    "        replacer = SpellingReplacer()\n",
    "        r = replacer.replace(item)\n",
    "        checked_list.append(r)\n",
    "    return checked_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    " word_list = ['car', 'Helo','hellp','venmo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['car', 'Help', 'hello', 'venom']\n"
     ]
    }
   ],
   "source": [
    "print(spell_check(word_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "\n",
    "DATA_DIR = './'   # navigation to the directory\n",
    "\n",
    "def load_df(json_path='name.json'):\n",
    "    \"\"\"\n",
    "    source: borrowed to kaggle competition gstore\n",
    "    \"\"\"\n",
    "    df = pd.read_json(DATA_DIR+json_path)\n",
    "    \n",
    "    for column in ['Issues']:\n",
    "        column_as_df = json_normalize(df[column])\n",
    "        column_as_df.columns = [str(column+\"_\"+subcolumn) for subcolumn in column_as_df.columns]\n",
    "        df = df.drop(column, axis=1).merge(column_as_df, right_index=True, left_index=True)\n",
    "    \n",
    "    ## function allows to keep the index if we need to merge on the orginal data.\n",
    "    df = pd.DataFrame([dict(y, index=i) for i, x in enumerate(df['Issues_Messages'].values.tolist()) for y in x])\n",
    "    \n",
    "    print(df.shape)\n",
    "    return df\n",
    "\n",
    "\n",
    "def splitDataFrameList(df,target_column,separator):\n",
    "    \n",
    "    ''' \n",
    "    source: https://gist.github.com/jlln/338b4b0b55bd6984f883 modified to keep punctuation\n",
    "    df = dataframe to split,\n",
    "    target_column = the column containing the values to split\n",
    "    separator = the symbol used to perform the split\n",
    "    returns: a dataframe with each entry for the target column separated, with each element moved into a new row. \n",
    "    The values in the other columns are duplicated across the newly divided rows.\n",
    "    '''\n",
    "    def split_text(line, separator):\n",
    "        splited_line =  [e+d for e in line.split(separator) if e]\n",
    "        return splited_line\n",
    "    \n",
    "    def splitListToRows(row,row_accumulator,target_column,separator):\n",
    "        split_row = row[target_column].split(separator)\n",
    "        for s in split_row:\n",
    "            new_row = row.to_dict()\n",
    "            new_row[target_column] = s\n",
    "            row_accumulator.append(new_row)\n",
    "    new_rows = []\n",
    "    df.apply(splitListToRows,axis=1,args = (new_rows,target_column,separator))\n",
    "    new_df = pd.DataFrame(new_rows)\n",
    "    return new_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Autocompleter:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def import_json(self, json_filename):   # converts json to dataframe\n",
    "        print(\"load json file...\")\n",
    "        df = load_df(json_filename)\n",
    "        return df\n",
    "        \n",
    "    def process_data(self, new_df):\n",
    "\n",
    "        print(\"select representative threads...\")\n",
    "        new_df = new_df[new_df.IsFromCustomer==False]\n",
    "        \n",
    "        print(\"split sentenses on punctuation...\")\n",
    "        for sep in ['. ',', ','? ', '! ', '; ']:\n",
    "            new_df = splitDataFrameList(new_df, 'Text', sep)\n",
    "            \n",
    "        print(\"Text Cleaning using simple regex...\")\n",
    "        new_df['Text']=new_df['Text'].apply(lambda x: \" \".join(x.split()))\n",
    "        new_df['Text']=new_df['Text'].apply(lambda x: x.strip(\".\"))\n",
    "        new_df['Text']=new_df['Text'].apply(lambda x: \" \".join(x.split()))\n",
    "        new_df['Text']=new_df['Text'].apply(lambda x: x.replace(' i ',' I '))\n",
    "        new_df['Text']=new_df['Text'].apply(lambda x: x.replace(' ?','?'))\n",
    "        new_df['Text']=new_df['Text'].apply(lambda x: x.replace(' !','!'))\n",
    "        new_df['Text']=new_df['Text'].apply(lambda x: x.replace(' .','.'))\n",
    "        new_df['Text']=new_df['Text'].apply(lambda x: x.replace('OK','Ok'))\n",
    "        new_df['Text']=new_df['Text'].apply(lambda x: x[0].upper()+x[1:])\n",
    "        new_df['Text']=new_df['Text'].apply(lambda x: x+\"?\" if re.search(r'^(Wh|How).+([^?])$',x) else x)\n",
    "        \n",
    "        print(\"calculate nb words of sentenses...\")\n",
    "        new_df['nb_words'] = new_df['Text'].apply(lambda x: len(str(x).split(' ')))\n",
    "        new_df = new_df[new_df['nb_words']>2]\n",
    "        \n",
    "        print(\"count occurence of sentenses...\")\n",
    "        new_df['Counts'] = new_df.groupby(['Text'])['Text'].transform('count')\n",
    "        \n",
    "        print(\"remove duplicates (keep last)...\")\n",
    "        new_df = new_df.drop_duplicates(subset=['Text'], keep='last')\n",
    "        \n",
    "        new_df = new_df.reset_index(drop=True)\n",
    "        print(new_df.shape)  \n",
    "        \n",
    "        return new_df\n",
    "    \n",
    "    def calc_matrice(self, df):\n",
    "        # define tfidf parameter in order to count/vectorize the description vector and then normalize it.\n",
    "        model_tf = TfidfVectorizer(analyzer='word',ngram_range=(1, 5), min_df=0)\n",
    "        tfidf_matrice = model_tf.fit_transform(df['Text'])\n",
    "        print(\"tfidf_matrice \", tfidf_matrice.shape)\n",
    "        return model_tf, tfidf_matrice\n",
    "\n",
    "    def generate_completions(self, prefix_string, data, model_tf, tfidf_matrice):\n",
    "        \n",
    "        prefix_string = str(prefix_string)              #make a copy of the prefix index\n",
    "        new_df = data.reset_index(drop=True)            #resets indexes to cover the removed elements\n",
    "        \n",
    "        #giving more weight to those phrases that occure more frequently\n",
    "        \n",
    "        weights = new_df['Counts'].apply(lambda x: 1+ np.log1p(x)).values      \n",
    "        \n",
    "       \n",
    "\n",
    "        # tranform the string using the tfidf model\n",
    "        tfidf_matrice_spelling = model_tf.transform([prefix_string])\n",
    "        # calculate cosine_matrix\n",
    "        # to find the similarity between the string and dataframe\n",
    "        cosine_similarite = linear_kernel(tfidf_matrice, tfidf_matrice_spelling)\n",
    "        \n",
    "        #sort by order of similarity from 1 to 0:\n",
    "        similarity_scores = list(enumerate(cosine_similarite))\n",
    "        similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "        #selects top 10\n",
    "        similarity_scores = similarity_scores[0:10]\n",
    "        #print (similarity_scores)\n",
    "\n",
    "        similarity_scores = [i for i in similarity_scores]\n",
    "        similarity_indices = [i[0] for i in similarity_scores]\n",
    "        #print(similarity_indices)\n",
    "        #print(similarity_scores)\n",
    "\n",
    "        #add weight to the potential results that had high frequency in orig data\n",
    "        for i in range(len(similarity_scores)):\n",
    "            similarity_scores[i][1][0]=similarity_scores[i][1][0]*weights[similarity_indices][i]\n",
    "        \n",
    "        #sort in terms of score\n",
    "\n",
    "        similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "        #select top 3 suggestions\n",
    "        similarity_scores = similarity_scores[0:3]\n",
    "        #obtain the indexes of the top suggestions\n",
    "        similarity_indices_w = [i[0] for i in similarity_scores]\n",
    "        \n",
    "        #print(similarity_scores)\n",
    "        #returns the top suggestions form the dataframe\n",
    "        return new_df.loc[similarity_indices_w]['Text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "autocompl = Autocompleter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load json file...\n",
      "(22264, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-48-7beb497e6d6b>:23: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n",
      "  column_as_df = json_normalize(df[column])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((22264, 3), Index(['IsFromCustomer', 'Text', 'index'], dtype='object'))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = autocompl.import_json(\"sample_file.json\")\n",
    "df.shape, df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select representative threads...\n",
      "split sentenses on punctuation...\n",
      "Text Cleaning using simple regex...\n",
      "calculate nb words of sentenses...\n",
      "count occurence of sentenses...\n",
      "remove duplicates (keep last)...\n",
      "(8560, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((8560, 5),\n",
       " Index(['IsFromCustomer', 'Text', 'index', 'nb_words', 'Counts'], dtype='object'))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "new_df = autocompl.process_data(df)\n",
    "new_df.shape, new_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf_matrice  (8560, 99397)\n",
      "TfidfVectorizer(min_df=0, ngram_range=(1, 5))   (0, 33836)\t0.22506411601749762\n",
      "  (0, 87558)\t0.23525303720560317\n",
      "  (0, 32778)\t0.23525303720560317\n",
      "  (0, 44183)\t0.22506411601749762\n",
      "  (0, 33835)\t0.2178349613878467\n",
      "  (0, 87557)\t0.23525303720560317\n",
      "  (0, 32777)\t0.23525303720560317\n",
      "  (0, 32959)\t0.1846205964173706\n",
      "  (0, 44182)\t0.2178349613878467\n",
      "  (0, 33834)\t0.2178349613878467\n",
      "  (0, 87556)\t0.23525303720560317\n",
      "  (0, 32774)\t0.22506411601749762\n",
      "  (0, 96514)\t0.16332887254348138\n",
      "  (0, 32868)\t0.11505321593595512\n",
      "  (0, 44181)\t0.2178349613878467\n",
      "  (0, 33830)\t0.2122275934232327\n",
      "  (0, 87552)\t0.22506411601749762\n",
      "  (0, 32773)\t0.22506411601749762\n",
      "  (0, 81915)\t0.1239111676844768\n",
      "  (0, 92912)\t0.04764879691120654\n",
      "  (0, 32780)\t0.10717536829998196\n",
      "  (0, 44108)\t0.15487367126385715\n",
      "  (0, 33739)\t0.1466392237166858\n",
      "  (0, 87551)\t0.2122275934232327\n",
      "  (0, 32760)\t0.2037723921436084\n",
      "  :\t:\n",
      "  (8559, 25383)\t0.12567308091854906\n",
      "  (8559, 68058)\t0.12541884066144987\n",
      "  (8559, 68057)\t0.12541884066144987\n",
      "  (8559, 49128)\t0.0888213424967633\n",
      "  (8559, 3207)\t0.14084282581837101\n",
      "  (8559, 3203)\t0.13280986104438153\n",
      "  (8559, 72151)\t0.0997213964987115\n",
      "  (8559, 7270)\t0.09223478035722917\n",
      "  (8559, 87763)\t0.08554413794890828\n",
      "  (8559, 87724)\t0.07433573183499405\n",
      "  (8559, 81356)\t0.11181636337439785\n",
      "  (8559, 49103)\t0.06048610671330503\n",
      "  (8559, 37889)\t0.08029750737646528\n",
      "  (8559, 49923)\t0.08789057063104239\n",
      "  (8559, 96785)\t0.09539041811857585\n",
      "  (8559, 87421)\t0.08493336394239505\n",
      "  (8559, 49593)\t0.05965420412809521\n",
      "  (8559, 68975)\t0.08771084920225622\n",
      "  (8559, 87560)\t0.05980497665272222\n",
      "  (8559, 36686)\t0.04710331142648342\n",
      "  (8559, 5585)\t0.04579479998300797\n",
      "  (8559, 71883)\t0.10075059701224119\n",
      "  (8559, 78959)\t0.03902986927144774\n",
      "  (8559, 3070)\t0.0666422895575152\n",
      "  (8559, 92912)\t0.029818130595719892\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_tf, tfidf_matrice = autocompl.calc_matrice(new_df)\n",
    "print (model_tf , tfidf_matrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is your     \n",
      " \n",
      "[(4938, array([0.62496768])), (7704, array([0.60085879])), (1723, array([0.5619263])), (3401, array([0.52970721])), (6526, array([0.52830733])), (4400, array([0.4896813])), (5326, array([0.48546842])), (8445, array([0.48546842])), (7694, array([0.48025837])), (6652, array([0.46864655]))]\n",
      "[(8445, array([2.32257299])), (6652, array([2.09285171])), (7694, array([1.78082213]))]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['What is your account number?',\n",
       " 'What is your order number?',\n",
       " 'What is your phone number?']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix = 'What is your'\n",
    "\n",
    "print(prefix,\"    \\n \")\n",
    "\n",
    "autocompl.generate_completions(prefix, new_df, model_tf,tfidf_matrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can      \n",
      "[(6303, array([0.55285577])), (7084, array([0.41376716])), (6285, array([0.36161791])), (8364, array([0.30942956])), (8376, array([0.29339882])), (6271, array([0.2367474])), (1747, array([0.17666316])), (2250, array([0.16287445])), (6693, array([0.15181223])), (6906, array([0.14698879]))]\n",
      "[(6303, array([0.93606619])), (7084, array([0.86833685])), (8364, array([0.64937268]))]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['How can I help you?',\n",
       " 'How can I help you today?',\n",
       " 'Ok lets see how I can help']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix = 'How can'\n",
    "print(prefix,\"     \")\n",
    "autocompl.generate_completions(prefix, new_df, model_tf,tfidf_matrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IsFromCustomer</th>\n",
       "      <th>Text</th>\n",
       "      <th>index</th>\n",
       "      <th>nb_words</th>\n",
       "      <th>Counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>Hello Werner how may I help you today?</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>Sure I can help you with that</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>Let me update that information on our system</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>I have updated your address to the system</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>Ok let me go ahead and request a work order fo...</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IsFromCustomer                                               Text  index  \\\n",
       "0           False             Hello Werner how may I help you today?      3   \n",
       "1           False                      Sure I can help you with that      3   \n",
       "2           False       Let me update that information on our system      3   \n",
       "3           False          I have updated your address to the system      3   \n",
       "4           False  Ok let me go ahead and request a work order fo...      3   \n",
       "\n",
       "   nb_words  Counts  \n",
       "0         8       1  \n",
       "1         7       1  \n",
       "2         8       1  \n",
       "3         8       1  \n",
       "4        14       1  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>IsFromCustomer</th>\n",
       "      <th>Text</th>\n",
       "      <th>index</th>\n",
       "      <th>nb_words</th>\n",
       "      <th>Counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Hello Werner how may I help you today?</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Sure I can help you with that</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>Let me update that information on our system</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>I have updated your address to the system</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>Ok let me go ahead and request a work order fo...</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8555</th>\n",
       "      <td>8555</td>\n",
       "      <td>False</td>\n",
       "      <td>Sorry for the wait</td>\n",
       "      <td>1505</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8556</th>\n",
       "      <td>8556</td>\n",
       "      <td>False</td>\n",
       "      <td>I can help you</td>\n",
       "      <td>1505</td>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8557</th>\n",
       "      <td>8557</td>\n",
       "      <td>False</td>\n",
       "      <td>I can help</td>\n",
       "      <td>1506</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8558</th>\n",
       "      <td>8558</td>\n",
       "      <td>False</td>\n",
       "      <td>Sorry to hear that I can help you with that</td>\n",
       "      <td>1507</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8559</th>\n",
       "      <td>8559</td>\n",
       "      <td>False</td>\n",
       "      <td>What is the flight number and the address of t...</td>\n",
       "      <td>1507</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8560 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      level_0  IsFromCustomer  \\\n",
       "0           0           False   \n",
       "1           1           False   \n",
       "2           2           False   \n",
       "3           3           False   \n",
       "4           4           False   \n",
       "...       ...             ...   \n",
       "8555     8555           False   \n",
       "8556     8556           False   \n",
       "8557     8557           False   \n",
       "8558     8558           False   \n",
       "8559     8559           False   \n",
       "\n",
       "                                                   Text  index  nb_words  \\\n",
       "0                Hello Werner how may I help you today?      3         8   \n",
       "1                         Sure I can help you with that      3         7   \n",
       "2          Let me update that information on our system      3         8   \n",
       "3             I have updated your address to the system      3         8   \n",
       "4     Ok let me go ahead and request a work order fo...      3        14   \n",
       "...                                                 ...    ...       ...   \n",
       "8555                                 Sorry for the wait   1505         4   \n",
       "8556                                     I can help you   1505         4   \n",
       "8557                                         I can help   1506         3   \n",
       "8558        Sorry to hear that I can help you with that   1507        10   \n",
       "8559  What is the flight number and the address of t...   1507        16   \n",
       "\n",
       "      Counts  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  \n",
       "...      ...  \n",
       "8555       9  \n",
       "8556      37  \n",
       "8557      20  \n",
       "8558       1  \n",
       "8559       1  \n",
       "\n",
       "[8560 rows x 6 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x99397 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tf.transform(['How can'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
